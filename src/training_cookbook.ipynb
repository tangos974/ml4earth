{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r training_requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll download the pretrained weights for the Swin Backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 444M/444M [00:13<00:00, 34.7MB/s] \n"
     ]
    }
   ],
   "source": [
    "from torchgeo.models import Swin_V2_B_Weights, swin_v2_b\n",
    "import torch\n",
    "\n",
    "dl_url = \"https://huggingface.co/allenai/satlas-pretrain/resolve/main/sentinel2_swinb_si_rgb.pth?download=true\"\n",
    "\n",
    "# Download model weights to ../data\n",
    "torch.hub.download_url_to_file(dl_url, \"../data/sentinel2_swinb_si_rgb.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can launch a run by placing ourselves in the root of the repo, and running the following command (runs should be started from the root of the repo):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Will launch a training run with the config set in config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-22 16:33:13 - \u001b[32mINFO\u001b[0m - Seed: 2\u001b[0m\n",
      "2024-09-22 16:33:13 - \u001b[32mINFO\u001b[0m - Run 2\u001b[0m\n",
      "2024-09-22 16:33:13 - \u001b[32mINFO\u001b[0m - paths: {'data_root': './data/landcoverai', 'runs_root': './runs', 'tensorboard_writer_folder': 'runs'}\u001b[0m\n",
      "2024-09-22 16:33:13 - \u001b[32mINFO\u001b[0m - preprocessing: {'image_size': [256, 256], 'mean': [0.3686, 0.3971, 0.3442], 'std': [0.1015, 0.0897, 0.0739], 'p_horizontal_flip': 0.5, 'rotation_degrees': 15, 'color_jitter': 0.2, 'scale': [0.66, 1.0], 'ratio': [0.75, 1.33], 'crop_prob': 0.2}\u001b[0m\n",
      "2024-09-22 16:33:13 - \u001b[32mINFO\u001b[0m - hyperparameters: {'batch_size': 16, 'num_workers': 8, 'num_classes': 5, 'epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'scheduler_mode': 'max', 'monitor': 'val_iou', 'scheduler_factor': 0.1, 'scheduler_patience': 5, 'gradient_accumulation_steps': 2, 'early_stopping_patience': 10, 'gradient_clip_val': 1.0, 'precision': 32}\u001b[0m\n",
      "2024-09-22 16:33:13 - \u001b[32mINFO\u001b[0m - model: {'name': 'SegmentationModel', 'pretrained_model_path': 'sentinel2_swinb_si_rgb.pth', 'return_nodes': {'features.0.0': 'stage1', 'features.2': 'stage2', 'features.4': 'stage3', 'features.6': 'stage4'}, 'in_channels_list': [128, 256, 512, 1024], 'fpn_out_channels': 256, 'expected_channels': {'stage1': 128, 'stage2': 256, 'stage3': 512, 'stage4': 1024}, 'upsample_scale': 32, 'freeze_backbone': True, 'num_layers_to_freeze': 4, 'class_weights': [0.04354043551738842, 2.932903987816641, 0.07613333623671328, 0.39044851850190576, 1.5569737219273523], 'label_smoothing': 0.1}\u001b[0m\n",
      "2024-09-22 16:33:13 - \u001b[32mINFO\u001b[0m - profiler: {'enabled': False}\u001b[0m\n",
      "2024-09-22 16:33:13 - \u001b[32mINFO\u001b[0m - Using device: cpu\u001b[0m\n",
      "2024-09-22 16:33:15 - \u001b[36mDEBUG\u001b[0m - Model architecture saved to runs/SegmentationModel_2/model_architecture.log\u001b[0m\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/tanguy/ml4earth/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/tanguy/ml4earth/.venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/tanguy/ml4earth/runs/SegmentationModel_2 exists and is not empty.\n",
      "┏━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName           \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[2m \u001b[0m\u001b[2m0 \u001b[0m\u001b[2m \u001b[0m│ model           │ SegmentationModel      │ 64.8 M │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m1 \u001b[0m\u001b[2m \u001b[0m│ criterion       │ CrossEntropyLoss       │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m2 \u001b[0m\u001b[2m \u001b[0m│ train_accuracy  │ MulticlassAccuracy     │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m3 \u001b[0m\u001b[2m \u001b[0m│ train_iou       │ MulticlassJaccardIndex │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m4 \u001b[0m\u001b[2m \u001b[0m│ train_precision │ MulticlassPrecision    │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m5 \u001b[0m\u001b[2m \u001b[0m│ train_recall    │ MulticlassRecall       │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m6 \u001b[0m\u001b[2m \u001b[0m│ train_f1        │ MulticlassF1Score      │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m7 \u001b[0m\u001b[2m \u001b[0m│ val_accuracy    │ MulticlassAccuracy     │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m8 \u001b[0m\u001b[2m \u001b[0m│ val_iou         │ MulticlassJaccardIndex │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m9 \u001b[0m\u001b[2m \u001b[0m│ val_precision   │ MulticlassPrecision    │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m10\u001b[0m\u001b[2m \u001b[0m│ val_recall      │ MulticlassRecall       │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m11\u001b[0m\u001b[2m \u001b[0m│ val_f1          │ MulticlassF1Score      │      0 │ train │\n",
      "└────┴─────────────────┴────────────────────────┴────────┴───────┘\n",
      "\u001b[1mTrainable params\u001b[0m: 62.7 M                                                        \n",
      "\u001b[1mNon-trainable params\u001b[0m: 2.1 M                                                     \n",
      "\u001b[1mTotal params\u001b[0m: 64.8 M                                                            \n",
      "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 259                                     \n",
      "\u001b[1mModules in train mode\u001b[0m: 427                                                      \n",
      "\u001b[1mModules in eval mode\u001b[0m: 0                                                         \n",
      "\u001b[2K\u001b[37mEpoch 0/0 \u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m0/467\u001b[0m \u001b[37m0:00:00 • -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mv_num: 2.000      \u001b[0mt/s\u001b[0m \n",
      "                                                              \u001b[37minference_time:   \u001b[0m\n",
      "                                                              \u001b[37m2.112 val_loss:   \u001b[0m\n",
      "                                                              \u001b[37m2.542             \u001b[0m\n",
      "                                                              \u001b[37mval_accuracy:     \u001b[0m\n",
      "                                                              \u001b[37m0.181 val_iou:    \u001b[0m\n",
      "                                                              \u001b[37m0.126             \u001b[0m\n",
      "                                                              \u001b[37mval_precision:    \u001b[0m\n",
      "                                                              \u001b[37m0.226 val_recall: \u001b[0m\n",
      "                                                              \u001b[37m0.181 val_f1:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/0 \u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m1/467\u001b[0m \u001b[37m0:00:06 • -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mv_num: 2.000      \u001b[0m\n",
      "                                                              \u001b[37minference_time:   \u001b[0m\n",
      "                                                              \u001b[37m2.112 val_loss:   \u001b[0m\n",
      "                                                              \u001b[37m2.542             \u001b[0m\n",
      "                                                              \u001b[37mval_accuracy:     \u001b[0m\n",
      "                                                              \u001b[37m0.181 val_iou:    \u001b[0m\n",
      "                                                              \u001b[37m0.126             \u001b[0m\n",
      "                                                              \u001b[37mval_precision:    \u001b[0m\n",
      "                                                              \u001b[37m0.226 val_recall: \u001b[0m\n",
      "                                                              \u001b[37m0.181 val_f1:     \u001b[0m\n",
      "\u001b[2K\u001b[37mEpoch 0/0 \u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m5/467\u001b[0m \u001b[37m0:00:26 • 0:37:51\u001b[0m \u001b[37m0.20it/s\u001b[0m \u001b[37mv_num: 2.000\u001b[0m[37m1/467\u001b[0m \u001b[37m0:00:06 • -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mv_num: 2.000\u001b[0m^C\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "\u001b[2K\u001b[37mEpoch 0/0 \u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m5/467\u001b[0m \u001b[37m0:00:26 • 0:37:51\u001b[0m \u001b[37m0.20it/s\u001b[0m \u001b[37mv_num: 2.000\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!cd .. && python3 src/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the training progress in tensorboard, we can use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.17.1 at http://localhost:6007/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tensorboard.main --logdir=runs --load_fast=false"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
